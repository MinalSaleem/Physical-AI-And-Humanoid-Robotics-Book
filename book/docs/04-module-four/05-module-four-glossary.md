---
id: 05-module-four-glossary
title: "Module 4 Glossary of Terms"
sidebar_label: "Glossary"
sidebar_position: 5
---

# Module 4: Vision-Language-Action (VLA) - Glossary

This glossary provides definitions for key terms and concepts introduced in Module 4.

## A

**Action (ROS 2)**: A structured communication mechanism in ROS 2 designed for long-running, goal-oriented tasks, providing goal requests, feedback during execution, and final results.

## C

**Cognitive Planning**: The process of translating high-level, often abstract, human intentions or goals into a concrete, executable sequence of steps or actions for a robot, often facilitated by Large Language Models.

**Computer Vision**: A field of artificial intelligence that enables computers and robotic systems to "see," interpret, and understand visual information from the world (e.g., images, video).

## H

**Human-Robot Interaction (HRI)**: The study and design of interfaces and interactions between humans and robots, aiming for intuitive, effective, and safe collaboration.

## L

**Large Language Model (LLM)**: An artificial intelligence model capable of understanding, processing, and generating human-like text, utilized in robotics for tasks like cognitive planning, natural language understanding, and decision-making.

## N

**Natural Language Understanding (NLU)**: A subfield of AI that focuses on enabling computers to understand the meaning and intent of human language, crucial for interpreting voice commands.

## O

**OpenAI Whisper**: A powerful, general-purpose speech recognition model developed by OpenAI that accurately transcribes spoken language into text, supporting various languages and robust to noise and accents.

## P

**Prompt Engineering**: The process of carefully designing and refining input prompts to Large Language Models to elicit desired outputs, particularly important for guiding LLMs in robotics tasks like planning.

## R

**Robot Manipulation**: The ability of a robot to physically interact with objects in its environment, including grasping, moving, and placing them, often requiring precise control and perception.

## S

**Speech-to-Text (STT)**: Technology that converts audio input (spoken language) into written text, a foundational component for voice-controlled robotic systems.

## V

**Vision-Language-Action (VLA)**: An interdisciplinary field combining computer vision (how a robot sees), natural language processing (how a robot understands/communicates), and robot control (how a robot acts) to enable intelligent and versatile robot behavior.

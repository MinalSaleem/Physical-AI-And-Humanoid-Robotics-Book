"use strict";(globalThis.webpackChunkbook=globalThis.webpackChunkbook||[]).push([[823],{454:e=>{e.exports=JSON.parse('{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"category","label":"Physical AI and Humanoid Robotics","items":[{"type":"category","label":"Module 1: The Robotic Nervous System (ROS 2)","items":[{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-one/01-ros2-middleware-intro","label":"Chapter 1: ROS 2 Middleware","docId":"module-one/01-ros2-middleware-intro","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-one/02-nodes-topics-services","label":"Chapter 2: Nodes, Topics, Services","docId":"module-one/02-nodes-topics-services","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-one/03-python-rclpy-integration","label":"Chapter 3: Python rclpy","docId":"module-one/03-python-rclpy-integration","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-one/04-urdf-humanoids","label":"Chapter 4: URDF for Humanoids","docId":"module-one/04-urdf-humanoids","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-one/05-module-one-glossary","label":"Glossary","docId":"module-one/05-module-one-glossary","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-one/01-ros2-middleware-intro"},{"type":"category","label":"Module 2: The Digital Twin (Gazebo & Unity)","items":[{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-two/01-physics-sim-env-building","label":"Chapter 1: Physics Sim & Env","docId":"module-two/01-physics-sim-env-building","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-two/02-gazebo-physics-collisions","label":"Chapter 2: Gazebo Physics","docId":"module-two/02-gazebo-physics-collisions","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-two/03-unity-rendering-hri","label":"Chapter 3: Unity Rendering & HRI","docId":"module-two/03-unity-rendering-hri","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-two/04-simulating-sensors","label":"Chapter 4: Simulating Sensors","docId":"module-two/04-simulating-sensors","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-two/05-module-two-glossary","label":"Glossary","docId":"module-two/05-module-two-glossary","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-two/01-physics-sim-env-building"},{"type":"category","label":"Module 3: The AI-Robot Brain (NVIDIA Isaac\u2122)","items":[{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-three/01-advanced-perception-training","label":"Chapter 1: Advanced Perception","docId":"module-three/01-advanced-perception-training","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-three/02-nvidia-isaac-sim","label":"Chapter 2: Isaac Sim","docId":"module-three/02-nvidia-isaac-sim","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-three/03-isaac-ros-vslam-navigation","label":"Chapter 3: Isaac ROS","docId":"module-three/03-isaac-ros-vslam-navigation","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-three/04-nav2-humanoid-path-planning","label":"Chapter 4: Nav2 Humanoid Path Planning","docId":"module-three/04-nav2-humanoid-path-planning","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-three/01-advanced-perception-training"},{"type":"category","label":"Module 4: Vision-Language-Action (VLA)","items":[{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-four/01-llms-robotics-convergence","label":"Chapter 1: LLMs & Robotics","docId":"module-four/01-llms-robotics-convergence","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-four/02-voice-to-action-whisper","label":"Chapter 2: Voice-to-Action","docId":"module-four/02-voice-to-action-whisper","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-four/03-cognitive-planning-llms-ros2","label":"Chapter 3: Cognitive Planning","docId":"module-four/03-cognitive-planning-llms-ros2","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-four/04-capstone-autonomous-humanoid","label":"Chapter 4: Capstone Project","docId":"module-four/04-capstone-autonomous-humanoid","unlisted":false},{"type":"link","href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-four/05-module-four-glossary","label":"Glossary","docId":"module-four/05-module-four-glossary","unlisted":false}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/module-four/01-llms-robotics-convergence"}],"collapsed":true,"collapsible":true,"href":"/Physical-AI-And-Humanoid-Robotics-Book/docs/intro"}]},"docs":{"intro":{"id":"intro","title":"Tutorial Intro","description":"Let\'s discover Docusaurus in less than 5 minutes.","sidebar":"tutorialSidebar"},"module-four/01-llms-robotics-convergence":{"id":"module-four/01-llms-robotics-convergence","title":"The Convergence of LLMs and Robotics","description":"Introduction","sidebar":"tutorialSidebar"},"module-four/02-voice-to-action-whisper":{"id":"module-four/02-voice-to-action-whisper","title":"Voice-to-Action: Using OpenAI Whisper for Voice Commands Generation","description":"Introduction","sidebar":"tutorialSidebar"},"module-four/03-cognitive-planning-llms-ros2":{"id":"module-four/03-cognitive-planning-llms-ros2","title":"Cognitive Planning: Using LLMs to Translate Natural Language into ROS 2 Actions","description":"Introduction","sidebar":"tutorialSidebar"},"module-four/04-capstone-autonomous-humanoid":{"id":"module-four/04-capstone-autonomous-humanoid","title":"Capstone Project: The Autonomous Humanoid","description":"Introduction","sidebar":"tutorialSidebar"},"module-four/05-module-four-glossary":{"id":"module-four/05-module-four-glossary","title":"Module 4 Glossary of Terms","description":"This glossary provides definitions for key terms and concepts introduced in Module 4.","sidebar":"tutorialSidebar"},"module-one/01-ros2-middleware-intro":{"id":"module-one/01-ros2-middleware-intro","title":"Introduction to ROS 2 Middleware for Robot Control","description":"What is ROS 2?","sidebar":"tutorialSidebar"},"module-one/02-nodes-topics-services":{"id":"module-one/02-nodes-topics-services","title":"ROS 2 Nodes, Topics, and Services Deep-Dive","description":"In ROS 2, applications are built as a collection of independent, interconnected processes called nodes. These nodes communicate with each other using various mechanisms, primarily topics for asynchronous data streaming and services for synchronous request/response interactions. Understanding these core communication patterns is fundamental to developing effective ROS 2 applications, especially when integrating with Python-based AI agents, as we\'ll explore in Chapter 3: Bridging Python Agents to ROS Controllers using rclpy.","sidebar":"tutorialSidebar"},"module-one/03-python-rclpy-integration":{"id":"module-one/03-python-rclpy-integration","title":"Bridging Python Agents to ROS Controllers using rclpy","description":"In the realm of AI-native robotics, Python is often the language of choice for developing intelligent agents due to its rich ecosystem of AI/ML libraries. To enable these Python agents to interact with ROS 2-powered robots, we use rclpy, the official Python client library for ROS 2. rclpy allows Python programs to create ROS 2 nodes, publish and subscribe to topics, call and provide services, and interact with parameters and actions. This enables seamless control of robotic systems, including complex humanoid robots, whose physical structure is often defined using URDF, as we will explore in Chapter 4: Understanding URDF (Unified Robot Description Format) for Humanoids.","sidebar":"tutorialSidebar"},"module-one/04-urdf-humanoids":{"id":"module-one/04-urdf-humanoids","title":"Understanding URDF (Unified Robot Description Format) for Humanoids","description":"The Unified Robot Description Format (URDF) is an XML format used in ROS to describe all aspects of a robot. It\'s a critical tool for working with robots, especially humanoids, as it allows you to define their kinematic and dynamic properties, visual appearance, and collision characteristics. A well-defined URDF is essential for simulation, motion planning, and robot visualization.","sidebar":"tutorialSidebar"},"module-one/05-module-one-glossary":{"id":"module-one/05-module-one-glossary","title":"Module 1 Glossary of Terms","description":"This glossary provides definitions for key terms and concepts introduced in Module 1.","sidebar":"tutorialSidebar"},"module-three/01-advanced-perception-training":{"id":"module-three/01-advanced-perception-training","title":"Advanced Perception and Training","description":"Introduction","sidebar":"tutorialSidebar"},"module-three/02-nvidia-isaac-sim":{"id":"module-three/02-nvidia-isaac-sim","title":"NVIDIA Isaac Sim: Photorealistic Simulation and Synthetic Data Generation","description":"Introduction to Isaac Sim and Omniverse","sidebar":"tutorialSidebar"},"module-three/03-isaac-ros-vslam-navigation":{"id":"module-three/03-isaac-ros-vslam-navigation","title":"Isaac ROS: Hardware-Accelerated VSLAM and Navigation","description":"Introduction to Isaac ROS","sidebar":"tutorialSidebar"},"module-three/04-nav2-humanoid-path-planning":{"id":"module-three/04-nav2-humanoid-path-planning","title":"Nav2: Path Planning for Bipedal Humanoid Movement","description":"Introduction to Nav2","sidebar":"tutorialSidebar"},"module-three/05-module-three-glossary":{"id":"module-three/05-module-three-glossary","title":"Module 3 Glossary of Terms","description":"This glossary provides definitions for key terms and concepts introduced in Module 3."},"module-two/01-physics-sim-env-building":{"id":"module-two/01-physics-sim-env-building","title":"Physics Simulation and Environment Building","description":"Introduction to Digital Twins","sidebar":"tutorialSidebar"},"module-two/02-gazebo-physics-collisions":{"id":"module-two/02-gazebo-physics-collisions","title":"Simulating Physics, Gravity, and Collisions in Gazebo","description":"Realistic physics simulation is fundamental to the digital twin concept. It allows engineers and researchers to test robot designs, control algorithms, and interaction with the environment in a virtual space that closely mimics the real world. Gazebo excels in this area, offering robust physics engines and extensive configuration options. For more advanced visualization and human-robot interaction, see Chapter 3 Simulating Sensors: LiDAR, Depth Cameras, and IMUs.","sidebar":"tutorialSidebar"},"module-two/03-unity-rendering-hri":{"id":"module-two/03-unity-rendering-hri","title":"High-Fidelity Rendering and Human-Robot Interaction in Unity","description":"While Gazebo provides robust physics simulation, Unity excels in high-fidelity rendering and creating interactive user experiences, making it an ideal platform for visually rich digital twins and advanced human-robot interaction (HRI) studies. Unity\'s powerful graphics engine, scripting capabilities, and extensive asset store allow for the creation of stunningly realistic virtual environments. This powerful combination of simulation and visualization becomes even more potent when integrating realistic sensor data, which will be covered in Chapter 4 LiDAR, Depth Cameras, and IMUs.","sidebar":"tutorialSidebar"},"module-two/04-simulating-sensors":{"id":"module-two/04-simulating-sensors","title":"Simulating Sensors: LiDAR, Depth Cameras, and IMUs","description":"Accurate sensor data is the lifeblood of AI-native robotics. Robots perceive their environment through a variety of sensors, and to effectively train and test AI algorithms in digital twin environments, simulating these sensors realistically is paramount. This chapter delves into the simulation of three common robotic sensors: LiDAR, Depth Cameras, and IMUs, across both Gazebo and Unity platforms.","sidebar":"tutorialSidebar"},"module-two/05-module-two-glossary":{"id":"module-two/05-module-two-glossary","title":"Module 2 Glossary of Terms","description":"This glossary provides definitions for key terms and concepts introduced in Module 2.","sidebar":"tutorialSidebar"},"tutorial-basics/congratulations":{"id":"tutorial-basics/congratulations","title":"Congratulations!","description":"You have just learned the basics of Docusaurus and made some changes to the initial template."},"tutorial-basics/create-a-blog-post":{"id":"tutorial-basics/create-a-blog-post","title":"Create a Blog Post","description":"Docusaurus creates a page for each blog post, but also a blog index page, a tag system, an RSS feed..."},"tutorial-basics/create-a-document":{"id":"tutorial-basics/create-a-document","title":"Create a Document","description":"Documents are groups of pages connected through:"},"tutorial-basics/create-a-page":{"id":"tutorial-basics/create-a-page","title":"Create a Page","description":"Add Markdown or React files to src/pages to create a standalone page:"},"tutorial-basics/deploy-your-site":{"id":"tutorial-basics/deploy-your-site","title":"Deploy your site","description":"Docusaurus is a static-site-generator (also called Jamstack)."},"tutorial-basics/markdown-features":{"id":"tutorial-basics/markdown-features","title":"Markdown Features","description":"Docusaurus supports Markdown and a few additional features."},"tutorial-extras/manage-docs-versions":{"id":"tutorial-extras/manage-docs-versions","title":"Manage Docs Versions","description":"Docusaurus can manage multiple versions of your docs."},"tutorial-extras/translate-your-site":{"id":"tutorial-extras/translate-your-site","title":"Translate your site","description":"Let\'s translate docs/intro.md to French."}}}}')}}]);